---
title: "Introduction to sparsebn"
author: "Bryon Aragam"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Introduction to sparsebn}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

Introduction goes here

## Example: Learning a Markov Chain

Suppose that the data is generated by a simple Markov chain:

$$X_1\to X_2\to X_3.$$

Assume unit influences between variables, i.e. $X_j\sim\mathcal{N}(0,1)$ and $X_{j} = X_{j-1} + \varepsilon$ with $\varepsilon\sim\mathcal{N}(0,1)$ for $j>1$. If $X=(X_1,X_2,X_3)$ then $X=B^TX+\varepsilon\sim\mathcal{N}(0,\Sigma)$, where we use the following parameters:

$$
B = \begin{pmatrix}
0 & 1 & 0 \\
0 & 0 & 1 \\
0 & 0 & 0
\end{pmatrix}, \quad
\Omega = \begin{pmatrix}
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & 0 & 1
\end{pmatrix}, \quad
\Sigma = \begin{pmatrix}
3 & 2 & 1 \\
2 & 2 & 1 \\
1 & 1 & 1
\end{pmatrix}.
$$

To generate data from this model, first define the covariance matrix:
```{r}
mean.vector <- rep(0, 3)
covariance.matrix <- rbind(c(3,2,1),
                           c(2,2,1),
                           c(1,1,1))
```

Then we can generate some data using `mvtnorm::rmvnorm`:
```{r}
gaussian.data <- mvtnorm::rmvnorm(n = 100, mean = mean.vector, sigma = covariance.matrix)
```

In order to use the methods in the sparsebn package, we need to indicate what kind of data we are working with by wrapping the data into a `sparsebnData` object:
```{r message=FALSE, warning=FALSE}
library("sparsebn")
dat <- sparsebnData(gaussian.data, type = "continuous")
```

Now we can use this data to estimate $B$:
```{r}
dags.out <- estimate.dag(data = dat, 
                         lambdas.length = 20, 
                         edge.threshold = 10, 
                         verbose = FALSE)
dags.out
```

Note that the output is a _solution path_ (stored internally as a `sparsebnPath` object), instead of a single estimate. In order to select a particular DAG, we need to do model selection (not implemented yet).

As expected, the third estimate in our solution path gives the correct estimate:
```{r}
dags.out[[3]]
get.adjacency.matrix(dags.out[[3]])
```

## Example: Bayesian network repository

For a less trivial example, we will try to reconstruct the pathfinder network from the [Bayesian network repository](http://www.bnlearn.com/bnrepository/#pathfinder). The pathfinder network has 109 nodes and 195 edges.

First, load the data and construct a covariance matrix:

```{r}
data(pathfinder)
A <- as.matrix(get.adjacency.matrix(pathfinder)) # pathfinder network as an adjacency matrix
id <- diag(rep(1, num.nodes(pathfinder)))        # 109x109 identity matrix
Sigma <- solve(t(id - A)) %*% id %*% solve(id - A)
```

For simplicity we set all of the edge weights and variances to 1. Next, generate some random data:

```{r}
set.seed(123)
nn <- 1000
gdata <- mvtnorm::rmvnorm(nn, sigma = Sigma)
```

Now we create a `sparsebnData` object (note that the data here has no interventions), and generate a large grid of regularization parameters for the solution path (see `?generate.lambdas`).

```{r message=FALSE, warning=FALSE}
dat <- sparsebnData(gdata, type = "c", ivn = NULL)
lambdas <- generate.lambdas(sqrt(nn), 0.05, lambdas.length = 50, scale = "linear")
out <- estimate.dag(data = dat, 
                    lambdas = lambdas,
                    edge.threshold = 500, 
                    verbose = FALSE)
out
```

Let's visualize the solution with 195 edges. For this, we use the `igraph` package:
```{r}
solution <- get.solution(out, edges=195)
plot(solution,
     layout = igraph::layout.circle(to_igraph(solution$edges)),
     vertex.label = NA,
     vertex.size = 5,
     vertex.color = gray(0.75),
     edge.color = gray(0),
     edge.width = 1,
     edge.arrow.size = .25)
```

For comparison, let's plot the original pathfinder graph. 
```{r}
plot(pathfinder,
     layout = igraph::layout.circle(to_igraph(pathfinder)),
     vertex.label = NA,
     vertex.size = 5,
     vertex.color = gray(0.75),
     edge.color = gray(0),
     edge.width = 1,
     edge.arrow.size = .25)
```

Note that the output of `estimate.dag` is a list of _graphs_, i.e. without weights. In order to do inference and estimate the weights in these graphs, use `estimate.parameters`:
```{r}
out.fit <- estimate.parameters(out, data = dat)
```

The output is a list of weights, one for each value of $\lambda$. The weights are given in terms of $(B,\Omega)$, corresponding to the list `list(coefs, vars)`. For example, we can see how the weight of the first node on the second changes as we decrease $\lambda$:
```{r}
unlist(lapply(out.fit, function(x) x$coefs[1,2]))
```
